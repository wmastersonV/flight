{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Hyper-parameter tuning </h1>\n",
    "\n",
    "In this notebook, you will learn how to carry out hyper-parameter tuning.\n",
    "\n",
    "This notebook takes several hours to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Environment variables for project and bucket </h2>\n",
    "\n",
    "Change the cell below to reflect your Project ID and bucket name. See Lab 3a for setup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'just-aloe-200223' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'synergi' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-east1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> 0. train locally </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 /content/datalab/synergi/sample/train.csv\n",
      "100 /content/datalab/synergi/sample/val.csv\n"
     ]
    }
   ],
   "source": [
    "! gsutil cp gs://synergi/train/us000000000000 ./train\n",
    "! gsutil cp gs://synergi/train/us000000000000 ./val\n",
    "\n",
    "!tail -n +2 ./train > ./tmp \n",
    "!head -n +100 ./tmp > ${PWD}/sample/train.csv\n",
    "!wc -l ${PWD}/sample/train.csv\n",
    "\n",
    "!tail -n +2 ./val > ./tmp \n",
    "!head -n +100 ./tmp > ${PWD}/sample/val.csv\n",
    "!wc -l ${PWD}/sample/val.csv\n",
    "\n",
    "!rm ./tmp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f88c38bce50>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/datalab/synergi/taxi_trained/', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f88c38bc210>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/datalab/synergi/taxi_trained/', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "2018-05-01 17:41:01.524716: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "bash: line 8:  1299 Killed                  python -m trainer.task --train_data_paths=\"${PWD}/sample/train*\" --eval_data_paths=${PWD}/sample/valid.csv --output_dir=${PWD}/taxi_trained --train_steps=1000 --job-dir=/tmp\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf taxifare.tar.gz taxi_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/taxifare\n",
    "python -m trainer.task \\\n",
    "  --train_data_paths=\"${PWD}/sample/train*\" \\\n",
    "  --eval_data_paths=${PWD}/sample/valid.csv  \\\n",
    "  --output_dir=${PWD}/taxi_trained \\\n",
    "  --train_steps=1000 \\\n",
    "  --job-dir=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# score\n",
    "\n",
    "# !ls taxi_trained/export/exporter/\n",
    "# %writefile /tmp/test.json\n",
    "# {\"dayofweek\": \"Sun\", \"hourofday\": 17, \"pickuplon\": -73.885262, \"pickuplat\": 40.773008, \"dropofflon\": -73.987232, \"dropofflat\": 40.732403, \"passengers\": 2}\n",
    "\n",
    "# model_dir=$(ls ${PWD}/taxi_trained/export/exporter)\n",
    "# gcloud ml-engine local predict \\\n",
    "#   --model-dir=${PWD}/taxi_trained/export/exporter/${model_dir} \\\n",
    "#   --json-instances=/tmp/test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train on cloud\n",
    "\n",
    "# %%bash\n",
    "# OUTDIR=gs://${BUCKET}/taxifare/ch4/taxi_trained\n",
    "# JOBNAME=lab4a_$(date -u +%y%m%d_%H%M%S)\n",
    "# echo $OUTDIR $REGION $JOBNAME\n",
    "# gsutil -m rm -rf $OUTDIR\n",
    "# gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "#   --region=$REGION \\\n",
    "#   --module-name=trainer.task \\\n",
    "#   --package-path=${PWD}/taxifare/trainer \\\n",
    "#   --job-dir=$OUTDIR \\\n",
    "#   --staging-bucket=gs://$BUCKET \\\n",
    "#   --scale-tier=BASIC \\\n",
    "#   --runtime-version=1.4 \\\n",
    "#   -- \\\n",
    "#   --train_data_paths=\"gs://$BUCKET/taxifare/ch4/taxi_preproc/train*\" \\\n",
    "#   --eval_data_paths=\"gs://${BUCKET}/taxifare/ch4/taxi_preproc/valid*\"  \\\n",
    "#   --train_steps=5000 \\\n",
    "#   --output_dir=$OUTDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> 1. Command-line parameters to task.py </h1>\n",
    "\n",
    "Note the command-line parameters to task.py.  These are the things that could be hypertuned if we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    parser.add_argument(\r\n",
      "        '--train_data_paths',\r\n",
      "        help = 'GCS or local path to training data',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--train_batch_size',\r\n",
      "        help = 'Batch size for training steps',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--eval_batch_size',\r\n",
      "        help = 'Batch size for evaluation steps',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--train_steps',\r\n",
      "        help = 'Steps to run the training job for',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--eval_steps',\r\n",
      "        help = 'Number of steps to run evalution for at each checkpoint',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--eval_data_paths',\r\n",
      "        help = 'GCS or local path to evaluation data',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--nbuckets',\r\n",
      "        help = 'Number of buckets into which to discretize lats and lons',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--hidden_units',\r\n",
      "        help = 'Hidden layer sizes to use for DNN feature columns -- provide space-separated layers',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--output_dir',\r\n",
      "        help = 'GCS location to write checkpoints and export models',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--job-dir',\r\n",
      "        help = 'this model ignores this field, but it is required by gcloud',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--eval_delay_secs',\r\n",
      "        help = 'How long to wait before running first evaluation',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--min_eval_frequency',\r\n",
      "        help = 'Minimum number of training steps between evaluations',\r\n",
      "--\r\n",
      "    parser.add_argument(\r\n",
      "        '--format',\r\n",
      "        help = 'Is the input data format csv or tfrecord?',\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A 2 add_argument taxifare/trainer/task.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> 2. Evaluation metric </h1>\n",
    "\n",
    "We add a special evaluation metric. It could be any objective function we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    estimator = tf.contrib.estimator.add_metrics(estimator, add_eval_metrics)\r\n",
      "    return estimator\r\n",
      "\r\n",
      "# Create feature engineering function that will be used in the input and serving input functions\r\n",
      "def add_engineered(features):\r\n",
      "    # this is how you can do feature engineering in TensorFlow\r\n",
      "--\r\n",
      "def add_eval_metrics(labels, predictions):\r\n",
      "    pred_values = predictions['predictions']\r\n",
      "    return {\r\n",
      "        'rmse': tf.metrics.root_mean_squared_error(labels, pred_values)\r\n",
      "    }\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A 5 add_eval_metrics taxifare/trainer/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> 3. Make sure outputs do not clobber each other </h1>\n",
    "\n",
    "We append the trial-number to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    # Append trial_id to path if we are doing hptuning\r\n",
      "    # This code can be removed if you are not using hyperparameter tuning\r\n",
      "    arguments['output_dir'] = os.path.join(\r\n",
      "        arguments['output_dir'],\r\n",
      "        json.loads(\r\n",
      "            os.environ.get('TF_CONFIG', '{}')\r\n",
      "        ).get('task', {}).get('trial', '')\r\n",
      "    ) \r\n",
      "\r\n",
      "    # Run the training job:\r\n",
      "    try:\r\n",
      "        model.train_and_evaluate(arguments)\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A 5 \"trial\" taxifare/trainer/task.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> 4. Create hyper-parameter configuration </h1>\n",
    "\n",
    "The file specifies the search region in parameter space.  Cloud MLE carries out a smart search algorithm within these constraints (i.e. it does not try out every single value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperparam.yaml\n"
     ]
    }
   ],
   "source": [
    "%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 3\n",
    "    hyperparameterMetricTag: rmse\n",
    "    params:\n",
    "    - parameterName: train_batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 64\n",
    "      maxValue: 512\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: nbuckets\n",
    "      type: INTEGER\n",
    "      minValue: 10\n",
    "      maxValue: 20\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"128 32\", \"256 128 16\", \"64 64 64 8\"]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> 5. Run the training job </h1>\n",
    "\n",
    "Just --config to the usual training command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://synergi/us_model us-east1 lab4a_180429_205608\n",
      "jobId: lab4a_180429_205608\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "/tools/google-cloud-sdk/lib/googlecloudsdk/core/util/files.py:622: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  for chunk in iter(lambda: fp.read(4096), ''):\n",
      "Job [lab4a_180429_205608] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe lab4a_180429_205608\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs lab4a_180429_205608\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/us_model\n",
    "JOBNAME=lab4a_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/taxifare/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://${BUCKET} \\\n",
    "   --scale-tier=STANDARD_1 \\\n",
    "   --runtime-version=1.4 \\\n",
    "   --config=hyperparam.yaml \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://$BUCKET/train/us*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/val/us*\"  \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2>6. Train chosen model on full dataset</h2>\n",
    "\n",
    "Look at the last section of the <a href=\"feateng.ipynb\">feature engineering notebook</a>.  The extra parameters are based on hyper-parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Copyright 2016 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "WARNING -- this uses significant resources and is optional. Remove this line to run the block.\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/taxifare/feateng2m\n",
    "JOBNAME=lab4a_$(date -u +%y%m%d_%H%M%S)\n",
    "TIER=STANDARD_1 \n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/taxifare/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=$TIER \\\n",
    "   --runtime-version=1.4 \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://cloud-training-demos/taxifare/train*\" \\\n",
    "   --eval_data_paths=\"gs://cloud-training-demos/taxifare/valid*\"  \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=418168 \\\n",
    "   --train_batch_size=512 --nbuckets=16 --hidden_units=\"64 64 64 8\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
